---
description: 
globs: 
alwaysApply: false
---
# Animus CLI Architecture

## Overview
Animus CLI is a Windows-based command-line tool for local Windows Event Log analysis. It combines PowerShell-based log collection with AI-powered log interpretation using Google's Gemini API. The system is designed to run entirely on the target Windows workstation, providing technicians with natural language insights about system events.

## Core Components

### 1. Main CLI Application (animus_cli/main.py)
- Entry point for the application
- Handles command-line argument parsing
- Manages the interactive Q&A loop
- Coordinates between log collection and LLM analysis
- Provides user interface and output formatting

### 2. Log Collection (powershell/collect_logs.ps1)
- PowerShell script for gathering Windows Event Logs
- Collects System, Application, and Security events
- Gathers system metadata and hardware information
- Outputs structured JSON format
- Configurable collection window (default 48 hours)

### 3. Log Processing (animus_cli/log_processor.py)
- Parses and structures the collected log data
- Provides data access and filtering methods
- Handles log file management
- Implements log summarization and analysis

### 4. LLM Integration (animus_cli/llm_manager.py)
- Manages interaction with Google's Gemini API
- Handles API key management
- Formats prompts for log analysis
- Processes and formats LLM responses

## Data Flow

1. Application Startup
   ```
   animus.bat
      │
      ▼
   main.py
      │
      ▼
   collect_logs.ps1 → animus_logs.json
      │
      ▼
   log_processor.py
      │
      ▼
   Interactive Q&A Loop
   ```

2. Log Collection Process
   - PowerShell script collects events from Windows Event Logs
   - Filters events based on time window and type
   - Gathers system information
   - Outputs structured JSON to %LOCALAPPDATA%\Animus

3. Log Processing
   - Loads and parses JSON log data
   - Provides structured access to events and metadata
   - Implements filtering and search capabilities
   - Manages log file lifecycle

4. LLM Analysis
   - Formats log data into prompts for Gemini API
   - Sends queries and receives responses
   - Processes and formats answers for display
   - Handles API errors and retries

## User Interface

### Command Line Interface
- Interactive prompt for questions
- Command history support
- Color-coded output
- Status messages and progress indicators

### Available Commands
- `refresh`: Recollect logs
- `exit`: End session
- `--hours`: Override collection window
- `--model-path`: Specify model location
- `--no-download`: Offline mode
- `--tiny`: Force lite model

## File Structure
```
animus_cli/
├── main.py           # Main application entry point
├── llm_manager.py    # Gemini API integration
├── log_processor.py  # Log data handling
└── __init__.py      # Package initialization

powershell/
└── collect_logs.ps1  # Log collection script

animus.bat           # Windows launcher script
```

## Deployment
- Single executable package built with PyInstaller
- Includes all Python dependencies
- Bundles PowerShell script
- Self-contained deployment
- No installation required

## Security Considerations
- Local-only execution
- No persistent background processes
- Optional cleanup of temporary files
- No data transmission to external servers (except Gemini API)
- API key management via environment variables

## Error Handling
- Graceful handling of missing logs
- API error recovery
- Memory management for large log files
- PowerShell execution policy handling
- File permission management

