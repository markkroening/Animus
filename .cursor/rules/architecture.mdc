---
description: 
globs: 
alwaysApply: false
---
# Animus CLI Architecture

## Overview
Animus CLI is a Windows-based command-line tool for local Windows Event Log analysis. It combines PowerShell-based log collection with AI-powered log interpretation using Google's Gemini API. The application is structured into several modules for better organization and maintainability.

## Core Components

### 1. Entry Point (`animus_cli/main.py`)
- **Purpose:** Main executable script and orchestrator.
- **Responsibilities:**
    - Loads environment variables and checks for API key presence.
    - Instantiates the `AnimusCLI` controller.
    - Always collects fresh logs on launch.
    - Always starts in interactive mode with the LLM.
    - Handles top-level application exit codes (0 for success, 1 for errors).
    - Provides helper functions for log collection and API key verification.
    - Accepts only the `--verbose` flag for debugging purposes.
    - Maintains a clean, minimal interface showing only the conversation with the LLM.

### 2. Configuration (`animus_cli/config.py`)
- **Purpose:** Centralized configuration and constants.
- **Responsibilities:**
    - Defines application version (`ANIMUS_VERSION`).
    - Determines execution context (script vs. bundle) using `IS_BUNDLED`.
    - Sets up base directories (`APP_BASE_DIR`, `BUNDLED_DATA_DIR`) based on execution context.
    - Defines key script paths (`SCRIPT_DIR`, `LOG_COLLECTOR_SCRIPT`).
    - Defines the default log output path (`DEFAULT_OUTPUT_PATH`) in user's LOCALAPPDATA.
    - Ensures the default log directory exists with error handling.
    - Configures the default LLM model (`DEFAULT_MODEL_NAME`).

### 3. Data Processing (`animus_cli/log_processor.py`)
- **Purpose:** Processes and analyzes log data to make it more efficient and LLM-friendly.
- **Key Class:**
    - `LogProcessor`: Handles log processing, filtering, and analysis with the following capabilities:
        - Processes raw log data from JSON output of `collect_logs.ps1`
        - Aggregates similar events to reduce redundancy
        - Generates comprehensive event summaries and statistics
        - Formats data for optimal LLM consumption
    - **Key Methods:**
        - `process_logs`: Main entry point that processes raw log data
        - `_aggregate_events`: Groups similar events by log name, provider, event ID, and level
        - `_generate_event_summary`: Creates statistical summaries of events
        - `format_for_llm`: Formats processed data for LLM consumption
        - `_normalize_level_name`: Standardizes event level names
    - **Features:**
        - Event aggregation with occurrence counts and timestamp tracking
        - Statistical analysis of events by type, level, and source
        - Top event source and ID identification
        - Timestamp normalization and sorting
        - Text cleaning and formatting for LLM consumption
        - Verbose logging support for debugging
    - **Data Structure:**
        - Works directly with dictionaries loaded from JSON
        - No intermediate data model classes
        - Input format matches PowerShell script output
        - Output format optimized for LLM consumption

### 4. Log Collector (`animus_cli/collector.py`)
- **Purpose:** Interfaces with the PowerShell log collection script.
- **Key Functions:**
    - `get_script_path`: Determines the correct path to `collect_logs.ps1` in different execution contexts:
        - Handles both bundled executable and source code execution
        - Checks multiple possible locations for the script
        - Provides detailed error messages for missing scripts
    - `collect_logs`: Executes the PowerShell script to collect Windows Event Logs:
        - Configures PowerShell execution with security bypass
        - Handles script execution with proper error capture
        - Verifies output file creation and content
        - Provides verbose output for debugging
        - Supports configurable collection parameters (hours back, max events)
    - **Error Handling:**
        - Validates script existence and accessibility
        - Handles PowerShell execution errors
        - Manages output directory creation
        - Provides detailed error messages and exit codes
    - **Features:**
        - Supports both development and production environments
        - Configurable log collection parameters
        - Comprehensive error reporting
        - Verbose mode for debugging
        - Output file validation

### 5. PowerShell Script (`animus_cli/scripts/collect_logs.ps1`)
- **Purpose:** Performs the actual Windows Event Log collection.
- **Responsibilities:**
    - Collects system information (OS version, hardware details).
    - Queries Windows Event Logs based on provided parameters.
    - Formats collected data into structured JSON output.
    - Handles error conditions and logging.
- **Key Features:**
    - **System Information Collection:**
        - OS details (version, build, display version)
        - Hardware specifications (model, manufacturer, memory)
        - System uptime and boot information
        - Installation date
    - **Network Information:**
        - Active network adapters
        - IP configurations (IPv4, IPv6)
        - DNS and gateway settings
        - MAC addresses
    - **Event Log Collection:**
        - Collects from System and Application logs
        - Configurable time range (hours back)
        - Configurable maximum events per log
        - Event filtering and formatting
    - **Output Handling:**
        - Structured JSON output
        - UTF-8 encoding without BOM
        - File verification and validation
        - Detailed error reporting
    - **Error Handling:**
        - Comprehensive try-catch blocks
        - Detailed error messages
        - Proper exit codes
        - Verbose logging support

### 6. CLI Controller (`animus_cli/cli.py`)
- **Purpose:** Encapsulates the core interactive and processing logic.
- **Key Class:**
    - `AnimusCLI`:
        - Initializes and manages the `LogCollection` state.
        - Initializes and manages the `LLMManager` instance (`_ensure_llm`).
        - Provides methods to load logs (`load_logs`), collect and load (`collect_and_load_logs`), show status (`show_status`), and process queries (`process_query`).
        - Implements the interactive Q&A loop (`run_interactive_mode`).
        - Handles interaction logic, basic command parsing within interactive mode, and calls to the LLM.
    - **Key Methods:**
        - `initialize_llm`: Sets up the LLM manager with proper error handling
        - `load_logs`: Loads and validates log data from JSON files
        - `process_query`: Handles natural language queries through the LLM
        - `main`: Entry point for CLI execution
    - **Features:**
        - Verbose mode support for debugging
        - Comprehensive error handling and logging
        - Interactive command-line interface
        - Support for both interactive and batch processing
        - Clean exit handling (Ctrl+C, quit commands)
    - **Error Handling:**
        - LLM initialization errors
        - Log loading failures
        - Query processing errors
        - Keyboard interrupt handling
        - Detailed error reporting in verbose mode

### 7. LLM Integration (`animus_cli/llm_manager.py`)
- **Purpose:** Manages interaction with the Google Gemini API.
- **Key Class:**
    - `LLMManager`:
        - Handles API key management and model initialization.
        - Formats prompts for log analysis.
        - Sends requests to the Gemini API.
        - Processes and returns the LLM's responses.
        - Handles API-specific errors (`GeminiAPIError`).
    - **Key Methods:**
        - `__init__`: Initializes the Gemini model with API key validation
        - `_format_query_content`: Prepares structured prompts with system context and log data
        - `query_logs`: Main method for processing queries with log data
        - `query`: Alternative method for pre-formatted text queries
    - **Features:**
        - Dynamic prompt generation with system context
        - Log data formatting and truncation
        - Response token management
        - Verbose mode for debugging
        - Safety filter handling
        - Performance timing
    - **Error Handling:**
        - API key validation
        - Model initialization errors
        - Response parsing errors
        - Safety filter blocks
        - Detailed error reporting
    - **Prompt Engineering:**
        - Personalized system context
        - Structured system information
        - Event log summary formatting
        - Clear instruction guidelines
        - Token limit management

## Data Flow

1.  **Startup (`main.py`)**:
    *   Checks for API key presence.
    *   Instantiates `AnimusCLI`.
    *   Initiates log collection.
    *   Sets up logging and error handling.
    *   Configures command-line arguments (only `--verbose` supported).

2.  **Log Acquisition**:
    *   `main.py` calls `collector.collect_logs`.
    *   `collector.py` locates and executes `collect_logs.ps1`:
        - Handles both bundled and source execution contexts
        - Validates script existence and accessibility
        - Configures PowerShell execution with security bypass
    *   `collect_logs.ps1` performs collection:
        - Gathers system information (OS, hardware, network)
        - Collects System and Application event logs
        - Formats data into structured JSON
        - Handles errors and provides verbose output
    *   Logs are processed by `LogProcessor`:
        - Aggregates similar events
        - Generates statistical summaries
        - Formats data for LLM consumption
        - Handles size limits and truncation
    *   Processed logs are stored in `LogCollection` object:
        - Maintains collection metadata
        - Provides access to system information
        - Manages event lists and statistics
        - Supports data conversion and summary generation

3.  **Interactive Mode**:
    *   `cli.py` manages the interactive session:
        - Initializes LLM manager
        - Handles user input and command parsing
        - Manages error handling and logging
        - Provides clean exit handling
    *   User queries are processed by `LLMManager`:
        - Formats prompts with system context
        - Prepares log data for LLM consumption
        - Handles API communication
        - Manages response processing
    *   Responses are formatted and displayed:
        - Handles safety filter blocks
        - Provides verbose output when enabled
        - Maintains clean interface
        - Preserves error messages

## File Structure
```
./
├── animus.bat           # Main launcher script
├── build_installer.bat  # Installer build script
├── Animus.iss          # Inno Setup configuration
├── requirements.txt     # Python dependencies
├── README.md           # Project documentation
├── LICENSE.txt         # License information
├── set_api_key.bat     # Script for setting the Gemini API key
├── set_api_key_silent.bat # Silent version of API key setting script
└── animus_cli/         # Main Python package
    ├── __init__.py       # Package marker
    ├── main.py           # Main application entry point
    ├── config.py         # Constants and configuration
    ├── data_models.py    # Dataclasses for log/system info
    ├── log_processor.py  # Log processing and analysis
    ├── collector.py      # PowerShell script execution logic
    ├── cli.py            # CLI interaction logic
    ├── llm_manager.py    # Gemini API integration
    └── scripts/
        └── collect_logs.ps1  # PowerShell log collection script
```

## Distribution Pipeline

Animus uses Inno Setup to create a professional Windows installer:

### Inno Setup
- **Purpose:** Creates a professional Windows installer
- **Configuration:** `Animus.iss` file
- **Output:** `output/AnimusSetup.exe` (Windows installer)
- **Features:**
    - Modern wizard interface
    - Administrative privileges required
    - Automatic PATH configuration
    - Desktop shortcut option
    - Silent installation support
    - Python dependency installation
    - Clean uninstallation

### Build Process
The build process is orchestrated by `build_installer.bat`, which:
1. Checks if Inno Setup is installed (downloads and installs if missing)
2. Validates required files and directories
3. Creates output directory if needed
4. Runs Inno Setup to create the installer
5. Places the final installer in the `output` directory
6. Provides detailed error reporting

## Security Considerations
- **API Key Management:**
    - Local execution and secure API key handling
    - API key stored in system environment variables
    - `set_api_key.bat` provides user-friendly key setting
    - `set_api_key_silent.bat` for automated deployment
    - No API key storage in application files
- **Log Collection:**
    - Secure PowerShell script execution with bypass policy
    - Limited event log access (System and Application only)
    - Configurable time range and event limits
    - Local-only log storage in user's AppData
- **Installation:**
    - Administrative privileges required
    - Verified file integrity during installation
    - Secure PATH modification
    - Clean uninstallation process

## Error Handling
- **Application-wide:**
    - Comprehensive error handling throughout the application
    - Custom exceptions for specific error cases
    - Verbose logging support for debugging
    - Clean exit codes (0 for success, 1 for errors)
- **Log Collection:**
    - PowerShell script error capture and reporting
    - File access and permission handling
    - Output validation and verification
    - Detailed error messages in verbose mode
- **LLM Integration:**
    - API key validation
    - Model initialization error handling
    - Response parsing and safety filter handling
    - Performance monitoring and timeout handling
- **Installation:**
    - Dependency verification
    - File existence checks
    - Installation directory validation
    - PATH modification verification

## Future Features

### 1. Tool Calling / Function Calling
- **Purpose:** Enable real-time system diagnostics through LLM-driven PowerShell command execution
- **Features:**
  - Safe execution of predefined PowerShell commands during conversations
  - Live system state information gathering
  - Example commands: `get_service_status`, `